"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[165],{930:function(e,t,s){s.d(t,{t2:function(){return e5}});var n=s(8375),r=s(8577),i=s(7488),o=s(5118),a=s(2586),l=s(1555);async function c(e,t){let s=await Promise.all([(0,r.yM)(e,"tokenizer.json",!0,t),(0,r.yM)(e,"tokenizer_config.json",!0,t)]);return null!==t.legacy&&(s[1].legacy=t.legacy),s}function h(e){let t=!(arguments.length>1)||void 0===arguments[1]||arguments[1];if(void 0!==e.Regex){let t=e.Regex.replace(/\\([#&~])/g,"$1");for(let[e,s]of f)t=t.replaceAll(e,s);return RegExp(t,"gu")}if(void 0===e.String)return console.warn("Unknown pattern type:",e),null;{let s=(0,n.hr)(e.String);return RegExp(t?s:"(".concat(s,")"),"gu")}}function u(e){return new Map(Object.entries(e))}function d(e){let t=e.dims;switch(t.length){case 1:return e.tolist();case 2:if(1!==t[0])throw Error("Unable to decode tensor with `batch size !== 1`. Use `tokenizer.batch_decode(...)` for batched inputs.");return e.tolist()[0];default:throw Error("Expected tensor to have 1-2 dimensions, got ".concat(t.length,"."))}}function _(e){return e.replace(/ \./g,".").replace(/ \?/g,"?").replace(/ \!/g,"!").replace(/ ,/g,",").replace(/ \' /g,"'").replace(/ n\'t/g,"n't").replace(/ \'m/g,"'m").replace(/ \'s/g,"'s").replace(/ \'ve/g,"'ve").replace(/ \'re/g,"'re")}function p(e){return e.replace(/[\u0300-\u036f]/g,"")}let g="\\p{P}\\u0021-\\u002F\\u003A-\\u0040\\u005B-\\u0060\\u007B-\\u007E",f=new Map([["(?i:'s|'t|'re|'ve|'m|'ll|'d)","(?:'([sS]|[tT]|[rR][eE]|[vV][eE]|[mM]|[lL][lL]|[dD]))"]]);class m{constructor(e){var t,s,n,r,i;this.content=e.content,this.id=e.id,this.single_word=null!==(t=e.single_word)&&void 0!==t&&t,this.lstrip=null!==(s=e.lstrip)&&void 0!==s&&s,this.rstrip=null!==(n=e.rstrip)&&void 0!==n&&n,this.special=null!==(r=e.special)&&void 0!==r&&r,this.normalized=null!==(i=e.normalized)&&void 0!==i?i:null}}class k extends n.Ag{static fromConfig(e){for(var t=arguments.length,s=Array(t>1?t-1:0),n=1;n<t;n++)s[n-1]=arguments[n];switch(e.type){case"WordPiece":return new x(e);case"Unigram":return new w(e,...s);case"BPE":return new b(e);default:if(e.vocab)return new z(e,...s);throw Error("Unknown TokenizerModel type: ".concat(e.type))}}_call(e){let t=this.encode(e);return this.fuse_unk&&(t=function(e,t,s){let n=[],r=0;for(;r<e.length;){var i,o;if(n.push(e[r]),(null!==(i=s.get(e[r]))&&void 0!==i?i:t)!==t){++r;continue}for(;r<e.length&&(null!==(o=s.get(e[r]))&&void 0!==o?o:t)===t;)++r}return n}(t,this.unk_token_id,this.tokens_to_ids)),t}encode(e){throw Error("encode should be implemented in subclass.")}convert_tokens_to_ids(e){return e.map(e=>{var t;return null!==(t=this.tokens_to_ids.get(e))&&void 0!==t?t:this.unk_token_id})}convert_ids_to_tokens(e){return e.map(e=>{var t;return null!==(t=this.vocab[e])&&void 0!==t?t:this.unk_token})}constructor(e){var t;super(),this.config=e,this.vocab=[],this.tokens_to_ids=new Map,this.unk_token_id=void 0,this.unk_token=void 0,this.end_of_word_suffix=void 0,this.fuse_unk=null!==(t=this.config.fuse_unk)&&void 0!==t&&t}}class x extends k{encode(e){let t=[];for(let s of e){let e=[...s];if(e.length>this.max_input_chars_per_word){t.push(this.unk_token);continue}let n=!1,r=0,i=[];for(;r<e.length;){let t=e.length,s=null;for(;r<t;){let n=e.slice(r,t).join("");if(r>0&&(n=this.config.continuing_subword_prefix+n),this.tokens_to_ids.has(n)){s=n;break}--t}if(null===s){n=!0;break}i.push(s),r=t}n?t.push(this.unk_token):t.push(...i)}return t}constructor(e){var t;for(let[s,n]of(super(e),this.tokens_to_ids=u(e.vocab),this.unk_token_id=this.tokens_to_ids.get(e.unk_token),this.unk_token=e.unk_token,this.max_input_chars_per_word=null!==(t=e.max_input_chars_per_word)&&void 0!==t?t:100,this.vocab=Array(this.tokens_to_ids.size),this.tokens_to_ids))this.vocab[n]=s}}class w extends k{populateNodes(e){let t=e.sentence,s=t.length,n=0;for(;n<s;){let s=!1,r=[];for(let i of this.trie.commonPrefixSearch(t.slice(n))){r.push(i);let t=this.tokens_to_ids.get(i),o=this.scores[t],a=i.length;e.insert(n,a,o,t),s||1!==a||(s=!0)}s||e.insert(n,1,this.unkScore,this.unk_token_id),n+=1}}tokenize(e){let t=new a.pQ(e,this.bosTokenId,this.eosTokenId);return this.populateNodes(t),t.tokens()}encode(e){let t=[];for(let s of e){let e=this.tokenize(s);t.push(...e)}return t}constructor(e,t){super(e);let s=e.vocab.length;this.vocab=Array(s),this.scores=Array(s);for(let t=0;t<s;++t){let s=e.vocab[t];this.vocab[t]=s[0],this.scores[t]=s[1]}this.unk_token_id=e.unk_id,this.unk_token=this.vocab[e.unk_id],this.tokens_to_ids=new Map(this.vocab.map((e,t)=>[e,t])),this.bosToken=" ",this.bosTokenId=this.tokens_to_ids.get(this.bosToken),this.eosToken=t.eos_token,this.eosTokenId=this.tokens_to_ids.get(this.eosToken),this.unkToken=this.vocab[this.unk_token_id],this.minScore=(0,i.VV)(this.scores)[0],this.unkScore=this.minScore-10,this.scores[this.unk_token_id]=this.unkScore,this.trie=new a.GA,this.trie.extend(this.vocab),this.fuse_unk=!0}}let v=(()=>{let e=[...Array.from({length:94},(e,t)=>t+33),...Array.from({length:12},(e,t)=>t+161),...Array.from({length:82},(e,t)=>t+174)],t=e.slice(),s=0;for(let n=0;n<256;++n)e.includes(n)||(e.push(n),t.push(256+s),s+=1);let n=t.map(e=>String.fromCharCode(e));return Object.fromEntries(e.map((e,t)=>[e,n[t]]))})(),y=(0,n.$2)(v);class b extends k{bpe(e){if(0===e.length)return[];let t=this.cache.get(e);if(void 0!==t)return t;let s=Array.from(e);this.end_of_word_suffix&&(s[s.length-1]+=this.end_of_word_suffix);let n=[];if(s.length>1){let e=new a.Z3((e,t)=>e.score<t.score),t={token:s[0],bias:0,prev:null,next:null},r=t;for(let t=1;t<s.length;++t){let n={bias:t/s.length,token:s[t],prev:r,next:null};r.next=n,this._add_node(e,r),r=n}for(;!e.isEmpty();){let s=e.pop();if(s.deleted||!s.next||s.next.deleted)continue;if(s.deleted=!0,s.next.deleted=!0,s.prev){let e={...s.prev};s.prev.deleted=!0,s.prev=e,e.prev?e.prev.next=e:t=e}let n={token:s.token+s.next.token,bias:s.bias,prev:s.prev,next:s.next.next};n.prev?(n.prev.next=n,this._add_node(e,n.prev)):t=n,n.next&&(n.next.prev=n,this._add_node(e,n))}for(let e=t;null!==e;e=e.next)n.push(e.token)}else n=s;if(this.continuing_subword_suffix)for(let e=0;e<n.length-1;++e)n[e]+=this.continuing_subword_suffix;return this.cache.set(e,n),n}_add_node(e,t){let s=this.bpe_ranks.get(t.token+this.BPE_SPLIT_TOKEN+t.next.token);void 0!==s&&(t.score=s+t.bias,e.push(t))}encode(e){let t=[];for(let s of e)for(let e of this.bpe(s))this.tokens_to_ids.has(e)?t.push(e):this.byte_fallback?t.push(...Array.from(this.text_encoder.encode(e)).map(e=>"<0x".concat(e.toString(16).toUpperCase().padStart(2,"0"),">"))):t.push(this.unk_token);return t}constructor(e){var t,s;for(let[t,s]of(super(e),this.BPE_SPLIT_TOKEN=" ",this.tokens_to_ids=u(e.vocab),this.unk_token_id=this.tokens_to_ids.get(e.unk_token),this.unk_token=e.unk_token,this.vocab=Array(this.tokens_to_ids.size),this.tokens_to_ids))this.vocab[s]=t;this.bpe_ranks=new Map(e.merges.map((e,t)=>[e,t])),this.merges=e.merges.map(e=>e.split(this.BPE_SPLIT_TOKEN)),this.end_of_word_suffix=e.end_of_word_suffix,this.continuing_subword_suffix=null!==(t=e.continuing_subword_suffix)&&void 0!==t?t:null,this.byte_fallback=null!==(s=this.config.byte_fallback)&&void 0!==s&&s,this.byte_fallback&&(this.text_encoder=new TextEncoder),this.cache=new Map}}class z extends k{encode(e){return e}constructor(e,t){for(let[s,n]of(super(e),this.tokens_to_ids=u(t.target_lang?e.vocab[t.target_lang]:e.vocab),this.bos_token=t.bos_token,this.bos_token_id=this.tokens_to_ids.get(this.bos_token),this.eos_token=t.eos_token,this.eos_token_id=this.tokens_to_ids.get(this.eos_token),this.pad_token=t.pad_token,this.pad_token_id=this.tokens_to_ids.get(this.pad_token),this.unk_token=t.unk_token,this.unk_token_id=this.tokens_to_ids.get(this.unk_token),this.vocab=Array(this.tokens_to_ids.size),this.tokens_to_ids))this.vocab[n]=s}}class A extends n.Ag{static fromConfig(e){if(null===e)return null;switch(e.type){case"BertNormalizer":return new F(e);case"Precompiled":return new eo(e);case"Sequence":return new N(e);case"Replace":return new S(e);case"NFC":return new E(e);case"NFKC":return new T(e);case"NFKD":return new C(e);case"Strip":return new M(e);case"StripAccents":return new P(e);case"Lowercase":return new R(e);case"Prepend":return new j(e);default:throw Error("Unknown Normalizer type: ".concat(e.type))}}normalize(e){throw Error("normalize should be implemented in subclass.")}_call(e){return this.normalize(e)}constructor(e){super(),this.config=e}}class S extends A{normalize(e){let t=h(this.config.pattern);return null===t?e:e.replaceAll(t,this.config.content)}}class E extends A{normalize(e){return e=e.normalize("NFC")}}class T extends A{normalize(e){return e=e.normalize("NFKC")}}class C extends A{normalize(e){return e=e.normalize("NFKD")}}class M extends A{normalize(e){return this.config.strip_left&&this.config.strip_right?e=e.trim():(this.config.strip_left&&(e=e.trimStart()),this.config.strip_right&&(e=e.trimEnd())),e}}class P extends A{normalize(e){return e=p(e)}}class R extends A{normalize(e){return e=e.toLowerCase()}}class j extends A{normalize(e){return e=this.config.prepend+e}}class N extends A{normalize(e){return this.normalizers.reduce((e,t)=>t.normalize(e),e)}constructor(e){super(e),this.normalizers=e.normalizers.map(e=>A.fromConfig(e))}}class F extends A{_tokenize_chinese_chars(e){let t=[];for(let s=0;s<e.length;++s){let n=e[s],r=n.charCodeAt(0);this._is_chinese_char(r)?(t.push(" "),t.push(n),t.push(" ")):t.push(n)}return t.join("")}_is_chinese_char(e){return e>=19968&&e<=40959||e>=13312&&e<=19903||e>=131072&&e<=173791||e>=173824&&e<=177983||e>=177984&&e<=178207||e>=178208&&e<=183983||e>=63744&&e<=64255||e>=194560&&e<=195103}stripAccents(e){return e.normalize("NFD").replace(/[\u0300-\u036f]/g,"")}_is_control(e){switch(e){case"	":case"\n":case"\r":return!1;default:return RegExp("^\\p{Cc}|\\p{Cf}|\\p{Co}|\\p{Cs}$","u").test(e)}}_clean_text(e){let t=[];for(let s of e){let e=s.charCodeAt(0);0===e||65533===e||this._is_control(s)||(/^\s$/.test(s)?t.push(" "):t.push(s))}return t.join("")}normalize(e){return this.config.clean_text&&(e=this._clean_text(e)),this.config.handle_chinese_chars&&(e=this._tokenize_chinese_chars(e)),this.config.lowercase?(e=e.toLowerCase(),!1!==this.config.strip_accents&&(e=this.stripAccents(e))):this.config.strip_accents&&(e=this.stripAccents(e)),e}}class L extends n.Ag{static fromConfig(e){if(null===e)return null;switch(e.type){case"BertPreTokenizer":return new U(e);case"Sequence":return new ea(e);case"Whitespace":return new el(e);case"WhitespaceSplit":return new ec(e);case"Metaspace":return new er(e);case"ByteLevel":return new O(e);case"Split":return new W(e);case"Punctuation":return new G(e);case"Digits":return new I(e);case"Replace":return new eh(e);default:throw Error("Unknown PreTokenizer type: ".concat(e.type))}}pre_tokenize_text(e,t){throw Error("pre_tokenize_text should be implemented in subclass.")}pre_tokenize(e,t){return(Array.isArray(e)?e.map(e=>this.pre_tokenize_text(e,t)):this.pre_tokenize_text(e,t)).flat()}_call(e,t){return this.pre_tokenize(e,t)}}class U extends L{pre_tokenize_text(e,t){return e.trim().match(this.pattern)||[]}constructor(e){super(),this.pattern=RegExp("[^\\s".concat(g,"]+|[").concat(g,"]"),"gu")}}class O extends L{pre_tokenize_text(e,t){return this.add_prefix_space&&!e.startsWith(" ")&&(e=" "+e),(this.use_regex?e.match(this.pattern)||[]:[e]).map(e=>Array.from(this.text_encoder.encode(e),e=>this.byte_encoder[e]).join(""))}constructor(e){var t;super(),this.config=e,this.add_prefix_space=this.config.add_prefix_space,this.trim_offsets=this.config.trim_offsets,this.use_regex=null===(t=this.config.use_regex)||void 0===t||t,this.pattern=RegExp("'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+","gu"),this.byte_encoder=v,this.text_encoder=new TextEncoder}}class W extends L{pre_tokenize_text(e,t){return null===this.pattern?[]:this.config.invert?e.match(this.pattern)||[]:function(e,t){let s=[],n=0;for(let r of e.matchAll(t)){let t=r[0];n<r.index&&s.push(e.slice(n,r.index)),t.length>0&&s.push(t),n=r.index+t.length}return n<e.length&&s.push(e.slice(n)),s}(e,this.pattern)}constructor(e){super(),this.config=e,this.pattern=h(this.config.pattern,this.config.invert)}}class G extends L{pre_tokenize_text(e,t){return e.match(this.pattern)||[]}constructor(e){super(),this.config=e,this.pattern=RegExp("[^".concat(g,"]+|[").concat(g,"]+"),"gu")}}class I extends L{pre_tokenize_text(e,t){return e.match(this.pattern)||[]}constructor(e){super(),this.config=e;let t="[^\\d]+|\\d".concat(this.config.individual_digits?"":"+");this.pattern=RegExp(t,"gu")}}class B extends n.Ag{static fromConfig(e){if(null===e)return null;switch(e.type){case"TemplateProcessing":return new Y(e);case"ByteLevel":return new K(e);case"RobertaProcessing":return new q(e);case"BertProcessing":return new D(e);default:throw Error("Unknown PostProcessor type: ".concat(e.type))}}post_process(e){for(var t=arguments.length,s=Array(t>1?t-1:0),n=1;n<t;n++)s[n-1]=arguments[n];throw Error("post_process should be implemented in subclass.")}_call(e){for(var t=arguments.length,s=Array(t>1?t-1:0),n=1;n<t;n++)s[n-1]=arguments[n];return this.post_process(e,...s)}constructor(e){super(),this.config=e}}class D extends B{post_process(e){let t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:null,{add_special_tokens:s=!0}=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{};s&&(e=(0,n.eG)([this.cls],e,[this.sep]));let r=Array(e.length).fill(0);if(null!==t){let i=s&&this instanceof q?[this.sep]:[],o=s?[this.sep]:[];e=(0,n.eG)(e,i,t,o),r=(0,n.eG)(r,Array(t.length+i.length+o.length).fill(1))}return{tokens:e,token_type_ids:r}}constructor(e){super(e),this.cls=e.cls[0],this.sep=e.sep[0]}}class q extends D{}class Y extends B{post_process(e){let t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:null,{add_special_tokens:s=!0}=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{},r=null===t?this.single:this.pair,i=[],o=[];for(let a of r)"SpecialToken"in a?s&&(i.push(a.SpecialToken.id),o.push(a.SpecialToken.type_id)):"Sequence"in a&&("A"===a.Sequence.id?(i=(0,n.eG)(i,e),o=(0,n.eG)(o,Array(e.length).fill(a.Sequence.type_id))):"B"===a.Sequence.id&&(i=(0,n.eG)(i,t),o=(0,n.eG)(o,Array(t.length).fill(a.Sequence.type_id))));return{tokens:i,token_type_ids:o}}constructor(e){super(e),this.single=e.single,this.pair=e.pair}}class K extends B{post_process(e){let t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:null;return t&&(e=(0,n.eG)(e,t)),{tokens:e}}}class $ extends n.Ag{static fromConfig(e){if(null===e)return null;switch(e.type){case"WordPiece":return new Q(e);case"Metaspace":return new ei(e);case"ByteLevel":return new X(e);case"Replace":return new Z(e);case"ByteFallback":return new V(e);case"Fuse":return new H(e);case"Strip":return new J(e);case"Sequence":return new et(e);case"CTC":return new ee(e);case"BPEDecoder":return new es(e);default:throw Error("Unknown Decoder type: ".concat(e.type))}}_call(e){return this.decode(e)}decode(e){return this.decode_chain(e).join("")}decode_chain(e){throw Error("`decode_chain` should be implemented in subclass.")}constructor(e){super(),this.config=e,this.added_tokens=[],this.end_of_word_suffix=null,this.trim_offsets=e.trim_offsets}}class Z extends ${decode_chain(e){let t=h(this.config.pattern);return null===t?e:e.map(e=>e.replaceAll(t,this.config.content))}}class V extends ${decode_chain(e){let t=[],s=[];for(let n of e){let e=null;if(6===n.length&&n.startsWith("<0x")&&n.endsWith(">")){let t=parseInt(n.slice(3,5),16);isNaN(t)||(e=t)}if(null!==e)s.push(e);else{if(s.length>0){let e=this.text_decoder.decode(Uint8Array.from(s));t.push(e),s=[]}t.push(n)}}if(s.length>0){let e=this.text_decoder.decode(Uint8Array.from(s));t.push(e),s=[]}return t}constructor(e){super(e),this.text_decoder=new TextDecoder}}class H extends ${decode_chain(e){return[e.join("")]}}class J extends ${decode_chain(e){return e.map(e=>{let t=0;for(let s=0;s<this.start;++s){if(e[s]===this.content){t=s+1;continue}break}let s=e.length;for(let t=0;t<this.stop;++t){let n=e.length-t-1;if(e[n]===this.content){s=n;continue}break}return e.slice(t,s)})}constructor(e){super(e),this.content=this.config.content,this.start=this.config.start,this.stop=this.config.stop}}class Q extends ${decode_chain(e){return e.map((e,t)=>(0!==t&&(e=e.startsWith(this.config.prefix)?e.replace(this.config.prefix,""):" "+e),this.cleanup&&(e=_(e)),e))}constructor(e){super(e),this.cleanup=e.cleanup}}class X extends ${convert_tokens_to_string(e){let t=e.join(""),s=new Uint8Array([...t].map(e=>this.byte_decoder[e]));return this.text_decoder.decode(s)}decode_chain(e){let t=[],s=[];for(let n of e)void 0!==this.added_tokens.find(e=>e.content===n)?(s.length>0&&(t.push(this.convert_tokens_to_string(s)),s=[]),t.push(n)):s.push(n);return s.length>0&&t.push(this.convert_tokens_to_string(s)),t}constructor(e){super(e),this.byte_decoder=y,this.text_decoder=new TextDecoder("utf-8",{fatal:!1,ignoreBOM:!0}),this.end_of_word_suffix=null}}class ee extends ${convert_tokens_to_string(e){if(0===e.length)return"";let t=[e[0]];for(let s=1;s<e.length;++s)e[s]!==t.at(-1)&&t.push(e[s]);let s=t.filter(e=>e!==this.pad_token).join("");return this.cleanup&&(s=_(s).replaceAll(this.word_delimiter_token," ").trim()),s}decode_chain(e){return[this.convert_tokens_to_string(e)]}constructor(e){super(e),this.pad_token=this.config.pad_token,this.word_delimiter_token=this.config.word_delimiter_token,this.cleanup=this.config.cleanup}}class et extends ${decode_chain(e){return this.decoders.reduce((e,t)=>t.decode_chain(e),e)}constructor(e){super(e),this.decoders=e.decoders.map(e=>$.fromConfig(e))}}class es extends ${decode_chain(e){return e.map((t,s)=>t.replaceAll(this.suffix,s===e.length-1?"":" "))}constructor(e){super(e),this.suffix=this.config.suffix}}class en extends ${decode_chain(e){let t="";for(let s=1;s<e.length;s+=2)t+=e[s];return[t]}}class er extends L{pre_tokenize_text(e){let{section_index:t}=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{},s=e.replaceAll(" ",this.strRep);return this.addPrefixSpace&&!s.startsWith(this.replacement)&&("always"===this.prepend_scheme||"first"===this.prepend_scheme&&0===t)&&(s=this.strRep+s),[s]}constructor(e){var t;super(),this.addPrefixSpace=e.add_prefix_space,this.replacement=e.replacement,this.strRep=e.str_rep||this.replacement,this.prepend_scheme=null!==(t=e.prepend_scheme)&&void 0!==t?t:"always"}}class ei extends ${decode_chain(e){let t=[];for(let s=0;s<e.length;++s){let n=e[s].replaceAll(this.replacement," ");this.addPrefixSpace&&0==s&&n.startsWith(" ")&&(n=n.substring(1)),t.push(n)}return t}constructor(e){super(e),this.addPrefixSpace=e.add_prefix_space,this.replacement=e.replacement}}class eo extends A{normalize(e){return e=(e=(e=e.replace(/[\u0001-\u0008\u000B\u000E-\u001F\u007F\u008F\u009F]/gm,"")).replace(/[\u0009\u000A\u000C\u000D\u1680\u200B\u200C\u200E\u200F\u2028\u2029\u2581\uFEFF\uFFFD]/gm," ")).includes("～")?e.split("～").map(e=>e.normalize("NFKC")).join("～"):e.normalize("NFKC")}constructor(e){super(e),this.charsmap=e.precompiled_charsmap}}class ea extends L{pre_tokenize_text(e,t){return this.tokenizers.reduce((e,s)=>s.pre_tokenize(e,t),[e])}constructor(e){super(),this.tokenizers=e.pretokenizers.map(e=>L.fromConfig(e))}}class el extends L{pre_tokenize_text(e,t){return e.match(/\w+|[^\w\s]+/g)||[]}constructor(e){super()}}class ec extends L{pre_tokenize_text(e,t){return e.match(/\S+/g)||[]}constructor(e){super()}}class eh extends L{pre_tokenize_text(e,t){return null===this.pattern?[e]:[e.replaceAll(this.pattern,this.config.content)]}constructor(e){super(),this.config=e,this.pattern=h(this.config.pattern),this.content=this.config.content}}let eu=["bos_token","eos_token","unk_token","sep_token","pad_token","cls_token","mask_token"];class ed extends n.Ag{getToken(){for(var e=arguments.length,t=Array(e),s=0;s<e;s++)t[s]=arguments[s];for(let e of t){let t=this._tokenizer_config[e];if(t){if("object"!=typeof t)return t;if("AddedToken"===t.__type)return t.content;throw Error("Unknown token: ".concat(t))}}return null}static async from_pretrained(e){let{progress_callback:t=null,config:s=null,cache_dir:n=null,local_files_only:r=!1,revision:i="main",legacy:o=null}=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};return new this(...await c(e,{progress_callback:t,config:s,cache_dir:n,local_files_only:r,revision:i,legacy:o}))}_call(e){let t,{text_pair:s=null,add_special_tokens:r=!0,padding:a=!1,truncation:l=null,max_length:c=null,return_tensor:h=!0}=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{},u=Array.isArray(e);if(u){if(0===e.length)throw Error("text array must be non-empty");if(null!==s){if(Array.isArray(s)){if(e.length!==s.length)throw Error("text and text_pair must have the same length")}else throw Error("text_pair must also be an array");t=e.map((e,t)=>this._encode_plus(e,s[t],{add_special_tokens:r}))}else t=e.map(e=>this._encode_plus(e,null,{add_special_tokens:r}))}else{if(null===e)throw Error("text may not be null");if(Array.isArray(s))throw Error("When specifying `text_pair`, since `text` is a string, `text_pair` must also be a string (i.e., not an array).");t=[this._encode_plus(e,s,{add_special_tokens:r})]}if(null===c?c="max_length"===a?this.model_max_length:(0,i.Fp)(t.map(e=>e.input_ids.length))[0]:l||console.warn("Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=true` to explicitly truncate examples to max length."),c=Math.min(c,this.model_max_length),a||l)for(let e=0;e<t.length;++e)t[e].input_ids.length!==c&&(t[e].input_ids.length>c?l&&function(e,t){for(let s of Object.keys(e))e[s].length=t}(t[e],c):a&&function(e,t,s,r){for(let i of Object.keys(e)){let o=t-e[i].length,a=s(i),l=Array(o).fill(a);e[i]="right"===r?(0,n.eG)(e[i],l):(0,n.eG)(l,e[i])}}(t[e],c,e=>"input_ids"===e?this.pad_token_id:0,this.padding_side));let d={};if(h){if(!(a&&l)&&t.some(e=>{for(let n of Object.keys(e)){var s;if(e[n].length!==(null===(s=t[0][n])||void 0===s?void 0:s.length))return!0}return!1}))throw Error("Unable to create tensor, you should probably activate truncation and/or padding with 'padding=true' and 'truncation=true' to have batched tensors with the same length.");let e=[t.length,t[0].input_ids.length];for(let s of Object.keys(t[0]))d[s]=new o.es("int64",BigInt64Array.from(t.flatMap(e=>e[s]).map(BigInt)),e)}else{for(let e of Object.keys(t[0]))d[e]=t.map(t=>t[e]);if(!u)for(let e of Object.keys(d))d[e]=d[e][0]}return d}_encode_text(e){return null===e?null:(this.added_tokens_regex?e.split(this.added_tokens_regex).filter(e=>e):[e]).map((e,t)=>{if(void 0!==this.added_tokens.find(t=>t.content===e))return e;{if(!0===this.remove_space&&(e=e.trim().split(/\s+/).join(" ")),this.do_lowercase_and_remove_accent&&(e=p(e.toLowerCase())),null!==this.normalizer&&(e=this.normalizer(e)),0===e.length)return[];let s=null!==this.pre_tokenizer?this.pre_tokenizer(e,{section_index:t}):[e];return this.model(s)}}).flat()}_encode_plus(e){let t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:null,{add_special_tokens:s=!0}=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{},r=this._encode_text(e),i=this._encode_text(t),o=this.post_processor?this.post_processor(r,i,{add_special_tokens:s}):{tokens:(0,n.eG)(null!=r?r:[],null!=i?i:[])},a=this.model.convert_tokens_to_ids(o.tokens),l={input_ids:a,attention_mask:Array(a.length).fill(1)};return this.return_token_type_ids&&o.token_type_ids&&(l.token_type_ids=o.token_type_ids),l}encode(e){let t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:null,{add_special_tokens:s=!0}=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{},{input_ids:n}=this._encode_plus(e,t,{add_special_tokens:s});return n}batch_decode(e){let t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};return e instanceof o.es&&(e=e.tolist()),e.map(e=>this.decode(e,t))}decode(e){let t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};if(e instanceof o.es&&(e=d(e)),!Array.isArray(e)||0===e.length||!(0,n.Wy)(e[0]))throw Error("token_ids must be a non-empty array of integers.");return this.decode_single(e,t)}decode_single(e,t){let{skip_special_tokens:s=!1,clean_up_tokenization_spaces:n=null}=t,r=this.model.convert_ids_to_tokens(e);s&&(r=r.filter(e=>!this.special_tokens.includes(e)));let i=this.decoder?this.decoder(r):r.join(" ");return this.decoder&&this.decoder.end_of_word_suffix&&(i=i.replaceAll(this.decoder.end_of_word_suffix," "),s&&(i=i.trim())),(null!=n?n:this.clean_up_tokenization_spaces)&&(i=_(i)),i}get default_chat_template(){return this._warned_about_chat_template||(console.warn("No chat template is defined for this tokenizer - using a default chat template that implements the ChatML format. If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information."),this._warned_about_chat_template=!0),this._default_chat_template}apply_chat_template(e){var t;let{chat_template:s=null,add_generation_prompt:n=!1,tokenize:r=!0,padding:i=!1,truncation:o=!1,max_length:a=null,return_tensor:c=!0}=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};null!=s||(s=null!==(t=this.chat_template)&&void 0!==t?t:this.default_chat_template);let h=this._compiled_template_cache.get(s);void 0===h&&(h=new l.YS(s),this._compiled_template_cache.set(s,h));let u=Object.create(null);for(let e of eu){let t=this.getToken(e);t&&(u[e]=t)}let d=h.render({messages:e,add_generation_prompt:n,...u});return r?this._call(d,{add_special_tokens:!1,padding:i,truncation:o,max_length:a,return_tensor:c}).input_ids:d}constructor(e,t){var s,r,i,o;for(let s of(super(),this.return_token_type_ids=!1,this._default_chat_template="{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% endif %}",this._tokenizer_config=t,this.normalizer=A.fromConfig(e.normalizer),this.pre_tokenizer=L.fromConfig(e.pre_tokenizer),this.model=k.fromConfig(e.model,t),this.post_processor=B.fromConfig(e.post_processor),this.decoder=$.fromConfig(e.decoder),this.special_tokens=[],this.all_special_ids=[],this.added_tokens=[],e.added_tokens)){let e=new m(s);this.added_tokens.push(e),this.model.tokens_to_ids.set(e.content,e.id),this.model.vocab[e.id]=e.content,e.special&&(this.special_tokens.push(e.content),this.all_special_ids.push(e.id))}this.additional_special_tokens=null!==(s=t.additional_special_tokens)&&void 0!==s?s:[],this.special_tokens.push(...this.additional_special_tokens),this.special_tokens=[...new Set(this.special_tokens)],this.decoder&&(this.decoder.added_tokens=this.added_tokens,this.decoder.end_of_word_suffix=this.model.end_of_word_suffix),this.added_tokens_regex=this.added_tokens.length>0?new RegExp(this.added_tokens.map(e=>"".concat(e.lstrip?"\\s*":"","(").concat((0,n.hr)(e.content),")").concat(e.rstrip?"\\s*":"")).join("|")):null,this.mask_token=this.getToken("mask_token"),this.mask_token_id=this.model.tokens_to_ids.get(this.mask_token),this.pad_token=this.getToken("pad_token","eos_token"),this.pad_token_id=this.model.tokens_to_ids.get(this.pad_token),this.sep_token=this.getToken("sep_token"),this.sep_token_id=this.model.tokens_to_ids.get(this.sep_token),this.unk_token=this.getToken("unk_token"),this.unk_token_id=this.model.tokens_to_ids.get(this.unk_token),this.model_max_length=t.model_max_length,this.remove_space=t.remove_space,this.clean_up_tokenization_spaces=null===(r=t.clean_up_tokenization_spaces)||void 0===r||r,this.do_lowercase_and_remove_accent=null!==(i=t.do_lowercase_and_remove_accent)&&void 0!==i&&i,this.padding_side="right",this.legacy=!1,this.chat_template=null!==(o=t.chat_template)&&void 0!==o?o:null,this._compiled_template_cache=new Map}}class e_ extends ed{constructor(...e){super(...e),this.return_token_type_ids=!0}}class ep extends ed{constructor(...e){super(...e),this.return_token_type_ids=!0}}class eg extends ed{constructor(...e){super(...e),this.return_token_type_ids=!0}}class ef extends ed{constructor(...e){super(...e),this.return_token_type_ids=!0}}class em extends ed{constructor(...e){super(...e),this.return_token_type_ids=!0}}class ek extends ed{constructor(...e){super(...e),this.return_token_type_ids=!0}}class ex extends ed{constructor(...e){super(...e),this.return_token_type_ids=!0}}class ew extends ed{constructor(...e){super(...e),this.return_token_type_ids=!0}}class ev extends ed{constructor(...e){super(...e),this.return_token_type_ids=!0}}class ey extends ed{}class eb extends ed{}class ez extends ed{constructor(e,t){super(e,t),this.return_token_type_ids=!0,console.warn('WARNING: `XLMTokenizer` is not yet supported by Hugging Face\'s "fast" tokenizers library. Therefore, you may experience slightly inaccurate results.')}}class eA extends ed{constructor(...e){super(...e),this.return_token_type_ids=!0}}class eS extends ed{}class eE extends ed{constructor(...e){super(...e),this._default_chat_template='{% for message in messages %}" "{{ message.content }}{{ eos_token }}" "{% endfor %}'}}class eT extends ed{}class eC extends ed{_build_translation_inputs(e,t,s){return eB(this,e,t,s)}constructor(e,t){super(e,t),this.languageRegex=/^[a-z]{2}_[A-Z]{2}$/,this.language_codes=this.special_tokens.filter(e=>this.languageRegex.test(e)),this.lang_to_token=e=>e}}class eM extends eC{}class eP extends ed{}class eR extends eE{constructor(e,t){var s,n;let r=".,!?…。，、।۔،",i=null===(n=e.pre_tokenizer)||void 0===n?void 0:null===(s=n.pretokenizers[0])||void 0===s?void 0:s.pattern;i&&i.Regex===" ?[^(\\s|[".concat(r,"])]+")&&(i.Regex=" ?[^\\s".concat(r,"]+")),super(e,t)}}class ej extends ed{_encode_text(e){if(null===e)return null;if(this.legacy||0===e.length)return super._encode_text(e);let t=super._encode_text("▁"+e.replaceAll("▁"," "));return t.length>1&&"▁"===t[0]&&this.special_tokens.includes(t[1])&&(t=t.slice(1)),t}get default_chat_template(){return super.default_chat_template.replaceAll("USE_DEFAULT_PROMPT",this.use_default_system_prompt?"true":"false").replaceAll("DEFAULT_SYSTEM_MESSAGE",this.DEFAULT_SYSTEM_PROMPT.replaceAll("\n","\\n").replaceAll("'","\\'"))}constructor(e,t){var s,n;super(e,t),this._default_chat_template="{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% elif USE_DEFAULT_PROMPT == true and not '<<SYS>>' in messages[0]['content'] %}{% set loop_messages = messages %}{% set system_message = 'DEFAULT_SYSTEM_MESSAGE' %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\n' + system_message + '\n<</SYS>>\n\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' %}{{ bos_token + '[INST] ' + content.strip() + ' [/INST]' }}{% elif message['role'] == 'system' %}{{ '<<SYS>>\n' + content.strip() + '\n<</SYS>>\n\n' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content.strip() + ' ' + eos_token }}{% endif %}{% endfor %}",this.DEFAULT_SYSTEM_PROMPT="You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.",this.use_default_system_prompt=null!==(s=t.use_default_system_prompt)&&void 0!==s&&s,this.legacy=null===(n=t.legacy)||void 0===n||n,this.legacy||(this.normalizer=null,this.pre_tokenizer=new er({replacement:"▁",add_prefix_space:!0,prepend_scheme:"first"}))}}class eN extends ej{}class eF extends ed{}class eL extends ed{}class eU extends ed{}class eO extends ed{}class eW extends ed{}class eG extends ed{}class eI extends ed{constructor(...e){super(...e),this._default_chat_template="{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"}}function eB(e,t,s,n){if(!("language_codes"in e)||!Array.isArray(e.language_codes))throw Error("Tokenizer must have `language_codes` attribute set and it should be an array of language ids.");if(!("languageRegex"in e)||!(e.languageRegex instanceof RegExp))throw Error("Tokenizer must have `languageRegex` attribute set and it should be a regular expression.");if(!("lang_to_token"in e)||"function"!=typeof e.lang_to_token)throw Error("Tokenizer must have `lang_to_token` attribute set and it should be a function.");let r=n.src_lang,i=n.tgt_lang;if(!e.language_codes.includes(i))throw Error('Target language code "'.concat(i,'" is not valid. Must be one of: {').concat(e.language_codes.join(", "),"}"));if(void 0!==r){if(!e.language_codes.includes(r))throw Error('Source language code "'.concat(r,'" is not valid. Must be one of: {').concat(e.language_codes.join(", "),"}"));for(let t of e.post_processor.config.single)if("SpecialToken"in t&&e.languageRegex.test(t.SpecialToken.id)){t.SpecialToken.id=e.lang_to_token(r);break}}return n.forced_bos_token_id=e.model.convert_tokens_to_ids([e.lang_to_token(i)])[0],e._call(t,s)}class eD extends ed{_build_translation_inputs(e,t,s){return eB(this,e,t,s)}constructor(e,t){super(e,t),this.languageRegex=/^[a-z]{3}_[A-Z][a-z]{3}$/,this.language_codes=this.special_tokens.filter(e=>this.languageRegex.test(e)),this.lang_to_token=e=>e}}class eq extends ed{_build_translation_inputs(e,t,s){return eB(this,e,t,s)}constructor(e,t){super(e,t),this.languageRegex=/^__[a-z]{2,3}__$/,this.language_codes=this.special_tokens.filter(e=>this.languageRegex.test(e)).map(e=>e.slice(2,-2)),this.lang_to_token=e=>"__".concat(e,"__")}}let eY=[["en","english"],["zh","chinese"],["de","german"],["es","spanish"],["ru","russian"],["ko","korean"],["fr","french"],["ja","japanese"],["pt","portuguese"],["tr","turkish"],["pl","polish"],["ca","catalan"],["nl","dutch"],["ar","arabic"],["sv","swedish"],["it","italian"],["id","indonesian"],["hi","hindi"],["fi","finnish"],["vi","vietnamese"],["he","hebrew"],["uk","ukrainian"],["el","greek"],["ms","malay"],["cs","czech"],["ro","romanian"],["da","danish"],["hu","hungarian"],["ta","tamil"],["no","norwegian"],["th","thai"],["ur","urdu"],["hr","croatian"],["bg","bulgarian"],["lt","lithuanian"],["la","latin"],["mi","maori"],["ml","malayalam"],["cy","welsh"],["sk","slovak"],["te","telugu"],["fa","persian"],["lv","latvian"],["bn","bengali"],["sr","serbian"],["az","azerbaijani"],["sl","slovenian"],["kn","kannada"],["et","estonian"],["mk","macedonian"],["br","breton"],["eu","basque"],["is","icelandic"],["hy","armenian"],["ne","nepali"],["mn","mongolian"],["bs","bosnian"],["kk","kazakh"],["sq","albanian"],["sw","swahili"],["gl","galician"],["mr","marathi"],["pa","punjabi"],["si","sinhala"],["km","khmer"],["sn","shona"],["yo","yoruba"],["so","somali"],["af","afrikaans"],["oc","occitan"],["ka","georgian"],["be","belarusian"],["tg","tajik"],["sd","sindhi"],["gu","gujarati"],["am","amharic"],["yi","yiddish"],["lo","lao"],["uz","uzbek"],["fo","faroese"],["ht","haitian creole"],["ps","pashto"],["tk","turkmen"],["nn","nynorsk"],["mt","maltese"],["sa","sanskrit"],["lb","luxembourgish"],["my","myanmar"],["bo","tibetan"],["tl","tagalog"],["mg","malagasy"],["as","assamese"],["tt","tatar"],["haw","hawaiian"],["ln","lingala"],["ha","hausa"],["ba","bashkir"],["jw","javanese"],["su","sundanese"]],eK=new Map(eY),e$=new Map([...eY.map(e=>{let[t,s]=e;return[s,t]}),["burmese","my"],["valencian","ca"],["flemish","nl"],["haitian","ht"],["letzeburgesch","lb"],["pushto","ps"],["panjabi","pa"],["moldavian","ro"],["moldovan","ro"],["sinhalese","si"],["castilian","es"]]);class eZ extends ed{_decode_asr(e){let{return_timestamps:t=!1,return_language:s=!1,time_precision:n=null,force_full_sequences:r=!0}=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};if(null===n)throw Error("Must specify time_precision");let o=null,a="word"===t;function l(){return{language:o,timestamp:[null,null],text:""}}let c=[],h=l(),u=0,d=this.model.convert_tokens_to_ids(["<|notimestamps|>"])[0]+1,_=[],p=[],g=!1,f=null,m=new Set(this.all_special_ids);for(let s of e){let e=s.tokens,r=a?s.token_timestamps:null,k=null,x=d;if("stride"in s){let[t,r,i]=s.stride;if(u-=r,f=t-i,r&&(x=r/n+d),i)for(let t=e.length-1;t>=0;--t){let s=e[t];if(s>=d){if(null!==k&&(s-d)*n<f)break;k=s}}}let w=[],v=[];for(let s=0;s<e.length;++s){let f=e[s];if(m.has(f)){let e=this.decode([f]),s=eK.get(e.slice(2,-2));if(void 0!==s){if(null!==o&&s!==o&&!t){_.push(w);let e=this.findLongestCommonSequence(_)[0],t=this.decode(e);h.text=t,c.push(h),_=[],w=[],h=l()}o=h.language=s}}else if(f>=d){let e=(f-d)*n+u,t=(0,i.NM)(e,2);if(null!==k&&f>=k)g=!0;else if(g||_.length>0&&f<x)g=!1;else if(null===h.timestamp[0])h.timestamp[0]=t;else if(t===h.timestamp[0]);else{h.timestamp[1]=t,_.push(w),a&&p.push(v);let[e,s]=this.findLongestCommonSequence(_,p),n=this.decode(e);h.text=n,a&&(h.words=this.collateWordTimestamps(e,s,o)),c.push(h),_=[],w=[],p=[],v=[],h=l()}}else if(w.push(f),a){let e,t=(0,i.NM)(r[s]+u,2);e=s+1<r.length?(0,i.NM)(r[s+1]+u,2):null,v.push([t,e])}}if("stride"in s){let[e,t,n]=s.stride;u+=e-n}w.length>0?(_.push(w),a&&p.push(v)):_.every(e=>0===e.length)&&(h=l(),_=[],w=[],p=[],v=[])}if(_.length>0){if(r&&t)throw Error("Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.");let[e,s]=this.findLongestCommonSequence(_,p),n=this.decode(e);h.text=n,a&&(h.words=this.collateWordTimestamps(e,s,o)),c.push(h)}let k=Object.create(null),x=c.map(e=>e.text).join("");if(t||s){for(let e=0;e<c.length;++e){let n=c[e];t||delete n.timestamp,s||delete n.language}if(a){let e=[];for(let t of c)for(let s of t.words)e.push(s);k={chunks:e}}else k={chunks:c}}return[x,k]}findLongestCommonSequence(e){let t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:null,s=e[0],n=s.length,r=[],i=Array.isArray(t)&&t.length>0,o=i?[]:null,a=i?t[0]:null;for(let l=1;l<e.length;++l){let c=e[l],h=0,u=[n,n,0,0],d=c.length;for(let e=1;e<n+d;++e){let t=e/1e4,r=Math.max(0,n-e),i=Math.min(n,n+d-e),o=s.slice(r,i),a=Math.max(0,e-n),l=Math.min(d,e),_=c.slice(a,l);if(o.length!==_.length)throw Error("There is a bug within whisper `decode_asr` function, please report it. Dropping to prevent bad inference.");let p=o.filter((e,t)=>e===_[t]).length,g=p/e+t;p>1&&g>h&&(h=g,u=[r,i,a,l])}let[_,p,g,f]=u,m=Math.floor((p+_)/2),k=Math.floor((f+g)/2);r.push(...s.slice(0,m)),n=(s=c.slice(k)).length,i&&(o.push(...a.slice(0,m)),a=t[l].slice(k))}return(r.push(...s),i)?(o.push(...a),[r,o]):[r,[]]}collateWordTimestamps(e,t,s){let[n,r,i]=this.combineTokensIntoWords(e,s),o=[];for(let e=0;e<n.length;++e){let s=i[e];o.push({text:n[e],timestamp:[t[s.at(0)][0],t[s.at(-1)][1]]})}return o}combineTokensIntoWords(e,t){let s,n,r,i=arguments.length>2&&void 0!==arguments[2]?arguments[2]:"\"'“\xa1\xbf([{-",o=arguments.length>3&&void 0!==arguments[3]?arguments[3]:"\"'.。,，!！?？:：”)]}、";return["chinese","japanese","thai","lao","myanmar"].includes(t=null!=t?t:"english")?[s,n,r]=this.splitTokensOnUnicode(e):[s,n,r]=this.splitTokensOnSpaces(e),this.mergePunctuations(s,n,r,i,o)}decode(e,t){let s;return t&&t.decode_with_timestamps?(e instanceof o.es&&(e=d(e)),s=this.decodeWithTimestamps(e,t)):s=super.decode(e,t),s}decodeWithTimestamps(e,t){var s;let n=null!==(s=null==t?void 0:t.time_precision)&&void 0!==s?s:.02,r=Array.from(this.all_special_ids).at(-1)+1,o=[[]];for(let t of e)if(t>=r){let e=(0,i.NM)((t-r)*n,2);o.push("<|".concat(e,"|>")),o.push([])}else o[o.length-1].push(t);return(o=o.map(e=>"string"==typeof e?e:super.decode(e,t))).join("")}splitTokensOnUnicode(e){let t=this.decode(e,{decode_with_timestamps:!0}),s=[],n=[],r=[],i=[],o=[],a=0;for(let l=0;l<e.length;++l){let c=e[l];i.push(c),o.push(l);let h=this.decode(i,{decode_with_timestamps:!0});h.includes("�")&&"�"!==t[a+h.indexOf("�")]||(s.push(h),n.push(i),r.push(o),i=[],o=[],a+=h.length)}return[s,n,r]}splitTokensOnSpaces(e){let[t,s,n]=this.splitTokensOnUnicode(e),r=[],i=[],o=[],a=RegExp("^[".concat(g,"]$"),"gu");for(let e=0;e<t.length;++e){let l=t[e],c=s[e],h=n[e],u=c[0]>=this.model.tokens_to_ids.get("<|endoftext|>"),d=l.startsWith(" "),_=l.trim(),p=a.test(_);if(u||d||p||0===r.length)r.push(l),i.push(c),o.push(h);else{let e=r.length-1;r[e]+=l,i[e].push(...c),o[e].push(...h)}}return[r,i,o]}mergePunctuations(e,t,s,r,i){let o=structuredClone(e),a=structuredClone(t),l=structuredClone(s),c=o.length-2,h=o.length-1;for(;c>=0;)o[c].startsWith(" ")&&r.includes(o[c].trim())?(o[h]=o[c]+o[h],a[h]=(0,n.eG)(a[c],a[h]),l[h]=(0,n.eG)(l[c],l[h]),o[c]="",a[c]=[],l[c]=[]):h=c,--c;for(c=0,h=1;h<o.length;)!o[c].endsWith(" ")&&i.includes(o[h])?(o[c]+=o[h],a[c]=(0,n.eG)(a[c],a[h]),l[c]=(0,n.eG)(l[c],l[h]),o[h]="",a[h]=[],l[h]=[]):c=h,++h;return[o.filter(e=>e),a.filter(e=>e.length>0),l.filter(e=>e.length>0)]}get_decoder_prompt_ids(){let{language:e=null,task:t=null,no_timestamps:s=!0}=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},n=[];if(e){e=e.toLowerCase();let t=e$.get(e);if(void 0===t){if(eK.has(e))t=e;else{let t=2===e.length?eK.keys():eK.values();throw Error('Language "'.concat(e,'" is not supported. Must be one of: ').concat(JSON.stringify(t)))}}let s=this.model.tokens_to_ids.get("<|".concat(t,"|>"));if(void 0===s)throw Error('Unable to find language "'.concat(t,'" in model vocabulary. Please report this issue at https://github.com/xenova/transformers.js/issues/new/choose.'));n.push(s)}else n.push(null);if(t){if("transcribe"!==(t=t.toLowerCase())&&"translate"!==t)throw Error('Task "'.concat(t,'" is not supported. Must be one of: ["transcribe", "translate"]'));let e=this.model.tokens_to_ids.get("<|".concat(t,"|>"));if(void 0===e)throw Error('Unable to find task "'.concat(t,'" in model vocabulary. Please report this issue at https://github.com/xenova/transformers.js/issues/new/choose.'));n.push(e)}else n.push(null);if(s){let e=this.model.tokens_to_ids.get("<|notimestamps|>");if(void 0===e)throw Error('Unable to find "<|notimestamps|>" in model vocabulary. Please report this issue at https://github.com/xenova/transformers.js/issues/new/choose.');n.push(e)}return n.map((e,t)=>[t+1,e]).filter(e=>null!==e[1])}constructor(...e){super(...e),this._default_chat_template='{% for message in messages %}" "{{ message.content }}{{ eos_token }}" "{% endfor %}'}}class eV extends ed{}class eH extends ed{}class eJ extends ed{}class eQ extends ed{_encode_text(e){if(null===e)return null;let[t,...s]=e.trim().split(this.languageRegex);if(0===s.length)return super._encode_text(t);if(2===s.length){let[e,t]=s;return this.supported_language_codes.includes(e)||console.warn('Unsupported language code "'.concat(e,'" detected, which may lead to unexpected behavior. Should be one of: ').concat(JSON.stringify(this.supported_language_codes))),(0,n.eG)([e],super._encode_text(t))}}constructor(e,t){super(e,t),this.languageRegex=/^(>>\w+<<)\s*/g,this.supported_language_codes=this.model.vocab.filter(e=>this.languageRegex.test(e)),console.warn('WARNING: `MarianTokenizer` is not yet supported by Hugging Face\'s "fast" tokenizers library. Therefore, you may experience slightly inaccurate results.')}}class eX extends ed{}class e0 extends ed{constructor(...e){super(...e),this._default_chat_template="{% for message in messages %}{% if message['role'] == 'user' %}{{ ' ' }}{% endif %}{{ message['content'] }}{% if not loop.last %}{{ '  ' }}{% endif %}{% endfor %}{{ eos_token }}"}}class e1 extends e0{}class e2 extends ed{}class e3 extends ed{}class e8 extends ed{constructor(e,t){super(e,t),this.decoder=new en({})}}class e5{static async from_pretrained(e){var t,s;let{quantized:n=!0,progress_callback:r=null,config:i=null,cache_dir:o=null,local_files_only:a=!1,revision:l="main",legacy:h=null}=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{},[u,d]=await c(e,{quantized:n,progress_callback:r,config:i,cache_dir:o,local_files_only:a,revision:l,legacy:h}),_=null!==(s=null===(t=d.tokenizer_class)||void 0===t?void 0:t.replace(/Fast$/,""))&&void 0!==s?s:"PreTrainedTokenizer",p=this.TOKENIZER_CLASS_MAPPING[_];return p||(console.warn('Unknown tokenizer class "'.concat(_,'", attempting to construct from base class.')),p=ed),new p(u,d)}}e5.TOKENIZER_CLASS_MAPPING={T5Tokenizer:eS,DistilBertTokenizer:ey,CamembertTokenizer:eb,DebertaTokenizer:em,DebertaV2Tokenizer:ek,BertTokenizer:e_,HerbertTokenizer:ex,ConvBertTokenizer:ew,RoFormerTokenizer:ev,XLMTokenizer:ez,ElectraTokenizer:eA,MobileBertTokenizer:eg,SqueezeBertTokenizer:ef,AlbertTokenizer:ep,GPT2Tokenizer:eE,BartTokenizer:eT,MBartTokenizer:eC,MBart50Tokenizer:eM,RobertaTokenizer:eP,WhisperTokenizer:eZ,CodeGenTokenizer:eV,CLIPTokenizer:eH,SiglipTokenizer:eJ,MarianTokenizer:eQ,BloomTokenizer:eR,NllbTokenizer:eD,M2M100Tokenizer:eq,LlamaTokenizer:ej,CodeLlamaTokenizer:eN,XLMRobertaTokenizer:eF,MPNetTokenizer:eL,FalconTokenizer:eU,GPTNeoXTokenizer:eO,EsmTokenizer:eW,Wav2Vec2CTCTokenizer:eX,BlenderbotTokenizer:e0,BlenderbotSmallTokenizer:e1,SpeechT5Tokenizer:e2,NougatTokenizer:e3,VitsTokenizer:e8,Qwen2Tokenizer:eG,GemmaTokenizer:eI,PreTrainedTokenizer:ed}}}]);